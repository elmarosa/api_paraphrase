{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ======================\n",
    "# PATH MODEL\n",
    "# ======================\n",
    "# Corrected MODEL_DIR to point to the location where the best model was saved\n",
    "MODEL_DIR = \"/content/drive/MyDrive/UAS_DEEPL/mt5_19/best_mt5_paraphrase_simple\"\n",
    "assert os.path.exists(MODEL_DIR), \"Model directory not found\"\n",
    "\n",
    "# ======================\n",
    "# DEVICE\n",
    "# ======================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ======================\n",
    "# LOAD MODEL\n",
    "# ======================\n",
    "model = MT5ForConditionalGeneration.from_pretrained(MODEL_DIR)\n",
    "tokenizer = MT5Tokenizer.from_pretrained(MODEL_DIR)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded\")\n",
    "\n",
    "# ======================\n",
    "# INFERENCE CONFIG\n",
    "# ======================\n",
    "GEN_CFG_INFER = {\n",
    "    \"do_sample\": True,\n",
    "    \"num_beams\": 2,\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_p\": 0.9,\n",
    "    \"no_repeat_ngram_size\": 3,\n",
    "    \"repetition_penalty\": 1.25,\n",
    "}\n",
    "\n",
    "SIM_LOW  = 0.70\n",
    "SIM_HIGH = 0.85\n",
    "MAX_TRIES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f14e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ParaphraseInference:\n",
    "    def __init__(self, model, tokenizer, device):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    def _sentence_embedding(self, text):\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=128\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.encoder(**inputs)\n",
    "\n",
    "        # mean pooling\n",
    "        emb = outputs.last_hidden_state.mean(dim=1)\n",
    "        return emb\n",
    "\n",
    "    def _similarity(self, a, b):\n",
    "        emb_a = self._sentence_embedding(a)\n",
    "        emb_b = self._sentence_embedding(b)\n",
    "        return F.cosine_similarity(emb_a, emb_b).item()\n",
    "\n",
    "    def predict(self, text, max_length=64):\n",
    "        best_output = None\n",
    "        best_sim = 1.0\n",
    "\n",
    "        for _ in range(MAX_TRIES):\n",
    "            inputs = self.tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_length=max_length,\n",
    "                    **GEN_CFG_INFER\n",
    "                )\n",
    "\n",
    "            candidate = self.tokenizer.decode(\n",
    "                outputs[0],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "\n",
    "            sim = self._similarity(text, candidate)\n",
    "\n",
    "            # sim terlalu tinggi â†’ terlalu mirip\n",
    "            if SIM_LOW <= sim <= SIM_HIGH:\n",
    "                return candidate\n",
    "\n",
    "            # sim terendah disimpan sebagai fallback\n",
    "            if sim < best_sim:\n",
    "                best_sim = sim\n",
    "                best_output = candidate\n",
    "\n",
    "        return best_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d541539",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferencer = ParaphraseInference(model, tokenizer, device)\n",
    "\n",
    "print(\n",
    "    inferencer.predict(\n",
    "        \"Ketika Jepang mendarat di Indonesia pada Maret 1942.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b0af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from pyngrok import ngrok\n",
    "import threading, time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/paraphrase\", methods=[\"POST\"])\n",
    "def paraphrase():\n",
    "    data = request.get_json(force=True)\n",
    "\n",
    "    if not data or \"text\" not in data:\n",
    "        return jsonify({\"error\": \"Missing field 'text'\"}), 400\n",
    "\n",
    "    result = inferencer.predict(data[\"text\"])\n",
    "\n",
    "    return jsonify({\n",
    "        \"input\": data[\"text\"],\n",
    "        \"paraphrase\": result\n",
    "    })\n",
    "\n",
    "def run_flask():\n",
    "    app.run(\n",
    "        host=\"0.0.0.0\",\n",
    "        port=5000,\n",
    "        debug=False,\n",
    "        use_reloader=False\n",
    "    )\n",
    "\n",
    "# ðŸ”¹ Jalankan Flask di background\n",
    "threading.Thread(target=run_flask, daemon=True).start()\n",
    "time.sleep(3)\n",
    "\n",
    "# ðŸ”¹ Bersihkan tunnel lama (AMAN)\n",
    "try:\n",
    "    ngrok.kill()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ðŸ”¹ Auth ngrok\n",
    "ngrok.set_auth_token(\"36v3wHUtN08JAtwT9mfPOLzjhJV_4GfZnfYKkcXZWMRiwvCTx\")\n",
    "\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\"PUBLIC URL:\", public_url)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
